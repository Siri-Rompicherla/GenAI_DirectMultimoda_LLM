# GenAI_DirectMultimoda_LLM

# ğŸ§  Direct Multimodal LLM System  
### Enterprise-Scale Multimodal Reasoning (Without RAG)

---

## ğŸ“Œ Project Overview

This capstone project implements a **Direct Multimodal Large Language Model (LLM) pipeline** that enables users to ask natural language questions over multiple input modalities â€” without a separate retrieval (RAG) step.

The system directly processes and reasons over:

- ğŸ“„ Text documents (reports, manuals, notes)
- ğŸ–¼ï¸ Images (charts, diagrams)
- ğŸ™ï¸ Audio recordings (meetings, lectures)
- ğŸ“‘ PDFs (digital and scanned)

The objective is to simulate an enterprise AI assistant capable of reasoning across multimodal internal company data.

---

## ğŸ—ï¸ System Architecture

### ğŸ”¹ 1. Data Ingestion
Supports:
- Text files (.txt)
- Image files (.png, .jpg)
- Audio files (.wav, .mp3)
- PDF documents

### ğŸ”¹ 2. Preprocessing

| Modality | Tool Used | Purpose |
|-----------|------------|------------|
| Text | Python | Cleaning & formatting |
| Image | PIL | Resizing, RGB conversion |
| Audio | Whisper | Speech-to-text transcription |
| PDF | PyMuPDF / pdfplumber | Text extraction |

---

## ğŸ¤– Multimodal LLM

**Model Used:** Qwen-VL (Open-Source Multimodal LLM)

### Why Qwen-VL?
- Strong text + image reasoning
- Instruction-following capability
- HuggingFace ecosystem compatibility
- Open-source & locally deployable

Alternative models explored:
- LLaVA
- MiniGPT-4

---

## ğŸ”„ Processing Flow

User Query  
â¬‡  
Multimodal Inputs Preprocessed  
â¬‡  
Structured Prompt Construction  
â¬‡  
Direct Multimodal LLM Reasoning  
â¬‡  
Natural Language Response  

---

## ğŸ§  Prompt Engineering Strategy

To reduce hallucinations and improve grounding:

- Explicit instruction to use only provided inputs
- Clear separation of modalities in prompt
- Instruction to state when information is unavailable
- Optional step-by-step reasoning guidance

### Example Prompt Template

```text
You are an enterprise AI assistant.
Use ONLY the provided multimodal inputs.
If information is not present, clearly state it.

Text Context:
{extracted_text}

Image Context:
{image_input}

Audio Transcript:
{transcribed_audio}

User Question:
{query}
```

---

## ğŸ§ª Example Queries Demonstrated

### 1ï¸âƒ£ Revenue Drop Analysis  
**Modalities:** Text + Image  
**Query:** Why did revenue drop in Q3?  
**Observation:** Successfully linked chart decline with textual explanation.

---

### 2ï¸âƒ£ Meeting Confirmation  
**Modalities:** Audio Transcript  
**Query:** Was the product launch confirmed?  
**Observation:** Accuracy dependent on transcription quality.

---

### 3ï¸âƒ£ Architecture Diagram Explanation  
**Modalities:** Image  
**Query:** What is the role of the API gateway?  
**Observation:** Minor hallucination when diagram text was unclear.

---

### 4ï¸âƒ£ Budget Approval Validation  
**Modalities:** Text + Audio  
**Query:** Is the budget approved?  
**Observation:** Model struggled when modalities contained conflicting signals.

---

### 5ï¸âƒ£ Risk Identification  
**Modalities:** Text + Image + Audio  
**Query:** What risks were identified in the presentation?  
**Observation:** Structured prompting improved grounding.

---

## âš  Challenges Encountered

- Audio transcription noise affecting reasoning
- OCR inaccuracies in scanned PDFs
- Context length limitations
- Occasional visual hallucinations
- Need for strong prompt constraints

---

## ğŸ“Š Evaluation Summary

| Metric | Performance |
|--------|------------|
| Cross-modal reasoning | Good |
| Hallucination control | Moderate |
| Visual reasoning | Strong on clear diagrams |
| Audio robustness | Dependent on transcription |

---

## ğŸ› ï¸ Tech Stack

- Python
- HuggingFace Transformers
- Qwen-VL
- OpenAI Whisper
- PIL
- PyMuPDF / pdfplumber
- Jupyter Notebook

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ multimodal_pipeline.py
â”œâ”€â”€ data.zip
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Extract Input Files

```bash
unzip data.zip
```

### 3ï¸âƒ£ Run the Pipeline

```bash
python multimodal_pipeline.py
```

---

## ğŸ’¡ Future Improvements

- Add modality confidence scoring
- Improve OCR robustness
- Compare with RAG-based architecture
- Build interactive UI (Streamlit/Gradio)
- Add visual attention explanation

---

## ğŸ‘©â€ğŸ’» Author

Sirisha Rompicherla  
Software Engineer | AI & GenAI Practitioner  
Full Stack Developer | ML Enthusiast
